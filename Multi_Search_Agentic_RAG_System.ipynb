{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPV2dKEaRdsAYyOT+J2AevX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavun-KumarCH/AI-Enhanced-RAG-System-for-Automated-University-Course-Content-Generation/blob/main/Multi_Search_Agentic_RAG_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Search Agentic-RAG System\n",
        "### A system leveraging multiple knowledge retrieval tools for enhanced query processing.\n",
        "\n",
        "### Framework: LangChain  \n",
        "### LLM: OpenAI Models\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Tools Used\n",
        "\n",
        "### 1.1. Wiki\n",
        "**Medium:** Wikipedia API or LangChain Wiki API integration  \n",
        "Wiki is used to retrieve factual and broad knowledge across a variety of domains. It is especially effective for general knowledge queries or historical data, where a detailed explanation or background information is necessary.\n",
        "\n",
        "### 1.2. arxiv\n",
        "**Medium:** arxiv API for research paper retrieval  \n",
        "arxiv provides access to scientific papers, useful for academic queries, technical topics, or research-related requests. This allows the system to respond with cutting-edge research or deep technical insights from recent publications.\n",
        "\n",
        "### 1.3. Retriever\n",
        "**Medium:** LangChain's Retriever Components  \n",
        "The retriever serves as a tool for fetching relevant documents based on the embeddings of the query. It operates across multiple sources (Wiki, arxiv, etc.) and ensures that the LLM has the most relevant context for generating responses.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. LLM and LangChain Integration\n",
        "\n",
        "### 2.1. LLM: OpenAI Models\n",
        "**Medium:** OpenAI GPT-4 and fine-tuned variations via LangChain  \n",
        "The LLM generates responses based on the documents retrieved by the retriever. It can summarize, interpret, and produce detailed answers, factoring in the specific knowledge drawn from the sources (Wiki, arxiv) used by the retriever.\n",
        "\n",
        "### 2.2. LangChain Framework\n",
        "**Medium:** Chains and Agents for multi-modal data flow  \n",
        "LangChain orchestrates the system’s flow, handling how user queries are split between different tools. It manages which tool (Wiki, arxiv, etc.) is used based on the nature of the question and ensures that the retrieved data is processed properly by the LLM.\n",
        "\n",
        "- **Agentic Behavior:**  \n",
        "  Dynamic agents enable the system to act autonomously, selecting the best retriever based on context and intelligently processing multi-tool requests.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Future Enhancements\n",
        "\n",
        "### 3.1. Integration of Additional Data Sources\n",
        "**Medium:** APIs or Web Scraping via LangChain  \n",
        "Potential additions include sources like Google Scholar, GitHub, or other specialized databases that can enhance the system’s versatility across domains.\n",
        "\n",
        "### 3.2. Fine-tuning for Specific Tasks\n",
        "**Medium:** Custom fine-tuning of the LLM  \n",
        "Fine-tuned models could be introduced to optimize the system for niche tasks, such as legal research or medical information retrieval."
      ],
      "metadata": {
        "id": "iq0w6FppRUC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "Wb-bZtZvRLFh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNGXg_xdAybD"
      },
      "outputs": [],
      "source": [
        "!pip install --q arxiv wikipedia langchain_community langchain_openai faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load Dependencies\n",
        "import os\n",
        "from langchain import hub\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "from langchain_community.tools import WikipediaQueryRun, ArxivQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "\n",
        "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
        "\n",
        "# Load Environment Variable\n",
        "from google.colab import userdata\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "7yqc8vqbEUT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools"
      ],
      "metadata": {
        "id": "efC-DLbaKt-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Wikipedia Tool\n",
        "api_wrapper = WikipediaAPIWrapper(top_k_results = 1, doc_content_chars_max = 200)\n",
        "\n",
        "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
        "\n",
        "wiki_tool.name"
      ],
      "metadata": {
        "id": "wEXaeoi4GpcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Arxiv Tool\n",
        "# the website were all the research papers are being uploaded\n",
        "\n",
        "arxiv_api_wrapper = ArxivAPIWrapper()\n",
        "arxiv_tool = ArxivQueryRun(api_wrapper = arxiv_api_wrapper)\n",
        "\n",
        "arxiv_tool.name"
      ],
      "metadata": {
        "id": "Nw1hphMDKHVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retriever Vectorstore\n",
        "\n",
        "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
        "docs = loader.load()\n",
        "documents = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200).split_documents(docs)\n",
        "vector_db = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
        "\n",
        "retriever = vector_db.as_retriever()\n",
        "\n",
        "retriever"
      ],
      "metadata": {
        "id": "oyWqRXdoHf4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Retriever Tool\n",
        "retrival_tool = create_retriever_tool(retriever, \"langsmith_search\", \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\")\n",
        "\n",
        "retrival_tool.name"
      ],
      "metadata": {
        "id": "5pS3vm6gJUVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools =  [wiki_tool, arxiv_tool, retrival_tool]"
      ],
      "metadata": {
        "id": "AC7cZom0KlOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents"
      ],
      "metadata": {
        "id": "Ihk6NsBVLs8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@ Agent\n",
        "\n",
        "# Initialize the LLM Model\n",
        "llm = ChatOpenAI(\n",
        "    model = \"gpt-3.5-turbo-0125\",\n",
        "    temperature = 0.3,\n",
        "    top_p = 0.8,\n",
        "    max_tokens = 400,\n",
        ")\n",
        "\n",
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "# Intializing Agent\n",
        "Agent = create_openai_tools_agent(llm = llm,\n",
        "                                  tools = tools,\n",
        "                                  prompt = prompt)"
      ],
      "metadata": {
        "id": "ZvJTg0YOLas_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent Executor"
      ],
      "metadata": {
        "id": "-J6qxzMfN5yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Executor\n",
        "agent_executor = AgentExecutor(agent = Agent, tools = tools, verbose = True)"
      ],
      "metadata": {
        "id": "sDQVU8EdM0Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response's"
      ],
      "metadata": {
        "id": "FwU53XCKQ3XA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Retriver Tool Invoke\n",
        "question = {\"input\" : \"Tell me About LangSmith and LangSmith Graph Agents\"}\n",
        "response = agent_executor.invoke(question)\n",
        "\n",
        "# Render using Markdown\n",
        "Markdown(response['output'])"
      ],
      "metadata": {
        "id": "x499NDLjOSON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Wikipedia Tool Invoke\n",
        "question = {\"input\" : \"Tell me About GAN\"}\n",
        "response = agent_executor.invoke(question)\n",
        "\n",
        "# Render using Markdown\n",
        "Markdown(response['output'])"
      ],
      "metadata": {
        "id": "6O7aAcGjPs-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Arxiv Tool Invoke\n",
        "question = {\"input\" : \"What's the paper 1605.08386 about?\"}\n",
        "response = agent_executor.invoke(question)\n",
        "\n",
        "# Render using Markdown\n",
        "Markdown(response['output'])"
      ],
      "metadata": {
        "id": "m6LHYqpXQJIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}